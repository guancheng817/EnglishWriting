\documentclass[10pt,twocolumn,a4paper]{article}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx,float}
\usepackage{indentfirst}
\usepackage{balance}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}
\usepackage{geometry}
\usepackage{stfloats}
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\geometry{left=2.0cm,right=2.0cm,top=2.5cm,bottom=2.5cm}
\setlength{\parindent}{1em}
\title{The Method Overview of 6D Object Pose Estimation}
\author{Cheng Guan}
\date{\today}
\begin{document}
\maketitle
\section{Method Overview}

Before we describe our work in detail, we will introduce the task
 of 6D pose estimation formally and provide a high-level overview of our method.
 The objective is to ﬁnd the 6D pose $H_c=\left[ \emph{R}_c|\emph{t}_c \right]$ of object\emph{c}, with $\emph{R}_c$ (3$\times$3 matrix)
 describing a rotation around the object center and $\emph{t}_c$ (3×1 vector) representing the
 position of the object in camera space. The pose $H_c$ transforms each point in object
 coordinate space $ y \in \chi \subseteq \mathbb{R}^3$ into a point in camera space $ x \in \chi \subseteq \mathbb{R}^3$.

  Our algorithm consists of three stages(see Fig. ~\ref{fig1}). In the ﬁrst stage we
  densely predict object probabilities and object coordinates using a random forest.
   Instead of randomly sampling pose hypotheses as e.g. in \cite{brachmann2014learning} we use a
   graphical model to globally reason about hypotheses inliers.
   This second stage is described  roughly and later in detail.
   In the ﬁnal stage were ﬁneand rank our pose hypotheses to determine
   the best estimate.
   


   \subsection{Random Forest}
   We use the random forests from Brachmann \emph{et al.} \cite{brachmann2014learning}.
   Each tree \emph{T} of the forest $\tau$ predicts for each pixel an object probability and an object coordinate.
   As mentioned above, an object coordinate corresponds to a 3D point on the surface of the object.
   In our case we have \emph{T} = 3. As in \cite{brachmann2014learning} the object probabilities from multiple trees that are combined
   to one value using Bayes rule. This means that for a pixel \emph{i} and object \emph{c} we have the object
   probability $\emph{p}_c\left(i\right)$. The object probabilities can be seen as a soft segmentation mask.

  \subsection{Global Reasoning}
   In general, to estimate the pose of a rigid object, a minimal set of three correspondences
   between 3D points on the object and in the 3D scene is required .
   The 3D points on the object, \emph{i.e}. in the object coordinate system,
   are predicted by the random forest. One possible strategy is to generate such triplets
   randomly by RANSAC \cite{fischler1987random}, as proposed in \cite{brachmann2014learning}. However, this approach
   has a serious drawback: the number of triples which must be generated by RANSAC
    in order to have at least a correct triple with the probability of 95\%, is very high.
   Assuming that n out of N pixels contain correct correspondences, 
   the total number of samples is   $\frac{\log\left(1-0.95\right)}{\log\left(1-{\left( 1-n/N \right)}^3\right)}$. 
   For $\frac{n}{N}=0.05$ ,
   which corresponds to a state-of-the-artlocalclassiﬁer,this constitutes ~24.000.000 RANSAC iterations.
   Therefore, we address this problem with a different approach.
   Our goal is to assign to each pixel either one of the possible correspondence
   candidates, or an “outlier” label. We achieve this by formalizing a graphical
    model where each pixel is connected to every other pixel with a pairwise term. The pairwise term encodes a geometric check which is deﬁned later.
    
   \begin{figure}
  \centering
  \includegraphics[scale=0.3]{1.png}
  \caption{Our pipeline: Given an RGB-D image (a) a random forest provides two predictions: object probabilities and object coordinates (b). In a second stage our novel, fully-connected CRF infers pose-consistent pixel-sets (see zoom) (c). In the last stage, pose hypotheses given by pose-consistent pixels of the CRF are reﬁned and scored by an ICP-variant. The pose with the lowest score is given as output (d).
}
\label{fig1}
\end{figure}

  \subsection{Reﬁnement and Hypothesis Scoring}
  The output of the optimization of the graphical model is a collection of
  pose-consistent pixels where each of those pixels has a unique object coordinate.
  The collection is clustered into sets. In the example in Fig.~\ref{fig1}(c)
  there are two sets (red, green). Each set provides one pose hypothesis.
  These pose hypotheses are reﬁned and scored using our ICP-variant.
  In order to be robust to occlusion we only take the pose-consistent pixels within the ICP \cite{rusu20113d}
   for ﬁtting the 3D model.

  {\small
\bibliographystyle{ieee}
\bibliography{MethodOverview}
}
 \end{document}
